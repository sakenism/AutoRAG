# Define your Vector DB configurations with correct embedding format
vectordb:
  - name: nomic_embed
    db_type: chroma
    client_type: persistent
    embedding_model:
      type: ollama
      model_name: nomic-embed-text
    collection_name: nomic_embed
    path: ${PROJECT_DIR}/resources/chroma
    embedding_batch: 20
  
  - name: mxbai_embed
    db_type: chroma
    client_type: persistent
    embedding_model:
      type: ollama
      model_name: mxbai-embed-large
    collection_name: mxbai_embed
    path: ${PROJECT_DIR}/resources/chroma
    embedding_batch: 20

# Chunking configuration
chunking:
  modules:
    - module_type: llama_index_chunk
      chunk_method: [Token, Sentence]  # Testing two chunking methods
      chunk_size: [256, 512]          # Reasonable chunk sizes
      chunk_overlap: 24
      add_file_name: en

# RAG pipeline configuration - ONLY retrieval phase
node_lines:
  - node_line_name: retrieve_line
    nodes:
      - node_type: retrieval
        strategy:
          metrics: [retrieval_f1, retrieval_recall, retrieval_precision, retrieval_ndcg]
          speed_threshold: 30
        top_k: 3
        modules:
          - module_type: vectordb
            vectordb: nomic_embed
          - module_type: vectordb
            vectordb: mxbai_embed
          - module_type: bm25